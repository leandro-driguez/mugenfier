{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music Genre Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import wget\n",
    "import random\n",
    "import shutil\n",
    "import tarfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from pandas import DataFrame\n",
    "from keras import Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Flatten, Dense, Conv2D, MaxPool2D, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED_VALUE = 42\n",
    "\n",
    "# Fix seed to make training deterministic.\n",
    "random.seed(SEED_VALUE)\n",
    "np.random.seed(SEED_VALUE)\n",
    "tf.random.set_seed(SEED_VALUE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the GTZAN Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.getenv('COLAB_RELEASE_TAG'):\n",
    "    from google.colab import drive \n",
    "    drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREPROCESSING = False\n",
    "\n",
    "try:\n",
    "    if 'dataset' not in os.listdir('/content'):\n",
    "        os.mkdir('/content/dataset/')\n",
    "    pwd = os.getcwd()\n",
    "    os.chdir('/content/dataset/')\n",
    "\n",
    "    if 'preprocessing.tar.gz' not in os.listdir('.'):\n",
    "        if os.getenv('COLAB_RELEASE_TAG'):\n",
    "            if 'preprocessing.tar.gz' in os.listdir('/content/gdrive/MyDrive'):\n",
    "                shutil.copy2('/content/gdrive/MyDrive/preprocessing.tar.gz', '.')\n",
    "            else:\n",
    "                # make sure to download the GTZAN dataset from \"https://drive.google.com/file/d/1UdmqcrBw71EgOtCLy6ic_C6EDBz9KQt_/view?usp=share_link\"\n",
    "                # upload it to your own google drive for it to be copied in the previous if statement block\n",
    "                pass\n",
    "        else:\n",
    "            if pwd != '/content/dataset':\n",
    "                if 'preprocessing.tar.gz' in os.listdir(f'{pwd}/dataset'):\n",
    "                    shutil.copy2(f'{pwd}/dataset/preprocessing.tar.gz', '.')\n",
    "                else:\n",
    "                    raise Exception(\"Download the GTZAN dataset preprocessed.\")\n",
    "\n",
    "        tar = tarfile.open('preprocessing.tar.gz', 'r:gz')\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "finally:\n",
    "    GENRES = os.listdir('/content/dataset/preprocessing/mfcc')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(src: str, feature: str, test_size: float=0.3, \n",
    "              random_state: float = SEED_VALUE, shuffle: bool = True, \n",
    "              stratify: list = None):\n",
    "    \"\"\"\n",
    "        Divide the data set into three subsets, the training set, \\\n",
    "        the test set and the validation set.\n",
    "    \"\"\"\n",
    "    dataset = []\n",
    "    for genre in os.listdir(f'{src}/{feature}'):\n",
    "        for img in os.listdir(f'{src}/{feature}/{genre}'):\n",
    "            img = cv2.imread(f'{src}/{feature}/{genre}/{img}')\n",
    "            # img = cv2.resize(img, (256, 192))\n",
    "            img = np.array(img, dtype=np.float32)\n",
    "            dataset.append([img, genre])\n",
    "\n",
    "    df = DataFrame(data=np.array(dataset, dtype=object), columns=[feature, 'genre'])\n",
    "\n",
    "    one_hot = pd.get_dummies(df['genre'])\n",
    "\n",
    "    df = pd.concat([df, one_hot], axis=1)\n",
    "    df.drop(['genre'], axis=1, inplace=True)\n",
    "    \n",
    "    strat = df[stratify] if stratify else None\n",
    "    train_set, test_set = train_test_split(df, test_size=test_size, random_state=random_state, \n",
    "                     shuffle=shuffle, stratify=strat)\n",
    "    \n",
    "    strat = test_set[stratify] if stratify else None\n",
    "    test_set, val_set = train_test_split(test_set, test_size=0.5, random_state=random_state, \n",
    "                     shuffle=shuffle, stratify=strat)\n",
    "\n",
    "    return (np.array([tf.convert_to_tensor(img) for img in train_set['mfcc']]), train_set[GENRES]) \\\n",
    "        , (np.array([tf.convert_to_tensor(img) for img in test_set['mfcc']]), test_set[GENRES]) \\\n",
    "        , (np.array([tf.convert_to_tensor(img) for img in val_set['mfcc']]), val_set[GENRES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test), (X_val, y_val) = load_data('./preprocessing/', 'mfcc', stratify=GENRES)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(input_shape=(217, 334, 3), filters=16, kernel_size=(3,3), activation='relu', padding='same', strides=1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), activation='relu'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=256, activation='relu'))\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = []\n",
    "\n",
    "model_storage = '/content'\n",
    "\n",
    "if os.getenv('COLAB_RELEASE_TAG'):\n",
    "    model_storage = '/content/gdrive/MyDrive'\n",
    "\n",
    "if 'model_storage' not in os.listdir(model_storage):\n",
    "    os.mkdir(f'{model_storage}/model_storage')\n",
    "\n",
    "last_iter = 0\n",
    "\n",
    "if len(os.listdir(f'{model_storage}/model_storage')) > 0:\n",
    "    last_iter = sorted([int(model.removeprefix('model_').removesuffix('.keras'))\n",
    "        for model in os.listdir(f'{model_storage}/model_storage')], reverse=True)[0]\n",
    "    model = tf.keras.saving.load_model(f'{model_storage}/model_storage/model_{last_iter}.keras')\n",
    "\n",
    "for i in range(last_iter, 50):\n",
    "    history.append(model.fit(x=X_train, y=y_train, epochs=10, validation_data=(X_test, y_test)))\n",
    "    model.save(f'{model_storage}/model_storage/model_{i}.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
