{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music Genre Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install wget essentia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import wget\n",
    "import random\n",
    "import shutil\n",
    "import tarfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from pylab import imshow\n",
    "from essentia import Pool \n",
    "from pandas import DataFrame\n",
    "from keras import Sequential\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.losses import SparseCategoricalCrossentropy\n",
    "from keras.layers import Flatten, Dense, Conv2D, MaxPool2D\n",
    "from essentia.standard import FrameGenerator, MonoLoader, \\\n",
    "    Windowing, Spectrum, MFCC, UnaryOperator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED_VALUE = 42\n",
    "\n",
    "# Fix seed to make training deterministic.\n",
    "random.seed(SEED_VALUE)\n",
    "np.random.seed(SEED_VALUE)\n",
    "tf.random.set_seed(SEED_VALUE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the GTZAN Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive \n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREPROCESSING = False\n",
    "\n",
    "try:\n",
    "    if 'dataset' not in os.listdir('.'):\n",
    "        os.mkdir('./dataset/')\n",
    "    os.chdir('./dataset/')\n",
    "\n",
    "    if 'genres.tar.gz' not in os.listdir('.'):    \n",
    "        if os.getenv('COLAB_RELEASE_TAG'):\n",
    "            if 'preprocessing.tar.gz' in os.listdir('../gdrive/MyDrive'):\n",
    "                shutil.copy2('../gdrive/MyDrive/preprocessing.tar.gz', '.')\n",
    "                tar = tarfile.open('preprocesing.tar.gz', 'r:gz')\n",
    "                tar.extractall()\n",
    "                tar.close()\n",
    "            else:\n",
    "                # download the GTZAN dataset\n",
    "                wget.download(\"https://huggingface.co/datasets/marsyas/gtzan/resolve/main/data/genres.tar.gz\")\n",
    "        elif not 'genres.tar.gz' in os.listdir('.'):\n",
    "            raise Exception(\"Download the GTZAN dataset.\")\n",
    "        \n",
    "    # extract all dataset\n",
    "    if 'genres' not in os.listdir('.'):\n",
    "        tar = tarfile.open('genres.tar.gz', 'r:gz')\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "    if 'preprocessing' not in os.listdir('.'):\n",
    "        PREPROCESSING = True\n",
    "\n",
    "    if PREPROCESSING:\n",
    "        os.mkdir('./preprocessing')\n",
    "        os.mkdir('./preprocessing/mfcc')\n",
    "        os.mkdir('./preprocessing/mfcc_bands')\n",
    "        os.mkdir('./preprocessing/mfcc_bands_log')\n",
    "\n",
    "        # remove all unnecesary files\n",
    "        for genre in os.listdir('./genres'):\n",
    "            if genre.startswith('.'): \n",
    "                os.remove(f'./genres/{genre}')\n",
    "                continue\n",
    "            \n",
    "            if PREPROCESSING:\n",
    "                os.mkdir(f'./preprocessing/mfcc/{genre}')\n",
    "                os.mkdir(f'./preprocessing/mfcc_bands/{genre}')\n",
    "                os.mkdir(f'./preprocessing/mfcc_bands_log/{genre}')\n",
    "            \n",
    "            for wav in os.listdir(f'./genres/{genre}'):\n",
    "                if wav.startswith('._'):\n",
    "                    os.remove(f'./genres/{genre}/{wav}')\n",
    "\n",
    "        for file in os.listdir('.'):\n",
    "            if file.startswith('._'):\n",
    "                os.remove(file)\n",
    "\n",
    "finally:\n",
    "    os.chdir('..')\n",
    "    GENRES = os.listdir('./dataset/genres/')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (16, 9)\n",
    "\n",
    "def extract_mfcc(src: str, dst: str, name: str, genre: str):\n",
    "    # we start by instantiating the audio loader:\n",
    "    loader = MonoLoader(filename=src)\n",
    "\n",
    "    # and then we actually perform the loading:\n",
    "    audio = loader()\n",
    "\n",
    "    w = Windowing(type = 'hann')\n",
    "    spectrum = Spectrum()  # FFT() would return the complex FFT, here we just want the magnitude spectrum\n",
    "    mfcc = MFCC()\n",
    "    \n",
    "    logNorm = UnaryOperator(type='log')\n",
    "\n",
    "    pool = Pool()\n",
    "\n",
    "    for frame in FrameGenerator(audio, frameSize = 1024, hopSize = 512, startFromZero=True):\n",
    "        mfcc_bands, mfcc_coeffs = mfcc(spectrum(w(frame)))\n",
    "        pool.add('lowlevel.mfcc', mfcc_coeffs)\n",
    "        pool.add('lowlevel.mfcc_bands', mfcc_bands)\n",
    "        pool.add('lowlevel.mfcc_bands_log', logNorm(mfcc_bands))\n",
    "\n",
    "    imshow(pool['lowlevel.mfcc'].T[1:,:], aspect='auto', origin='lower', interpolation='none')\n",
    "    plt.axis('off')\n",
    "    plt.savefig(f'{dst}/mfcc/{genre}/{name}.png', bbox_inches='tight', pad_inches=0)\n",
    "\n",
    "    imshow(pool['lowlevel.mfcc_bands'].T, aspect = 'auto', origin='lower', interpolation='none')\n",
    "    plt.axis('off')\n",
    "    plt.savefig(f'{dst}/mfcc_bands/{genre}/{name}.png', bbox_inches='tight', pad_inches=0)\n",
    "\n",
    "    imshow(pool['lowlevel.mfcc_bands_log'].T, aspect = 'auto', origin='lower', interpolation='none')\n",
    "    plt.axis('off')\n",
    "    plt.savefig(f'{dst}/mfcc_bands_log/{genre}/{name}.png', bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 1\n",
    "\n",
    "# extract features from the data set\n",
    "for genre in ['jazz', 'rock']:\n",
    "    for wav in os.listdir(f'./dataset/genres/{genre}'):\n",
    "        if PREPROCESSING:\n",
    "            try: \n",
    "                extract_mfcc(\n",
    "                    src=f'./dataset/genres/{genre}/{wav}', \n",
    "                    dst=f'./dataset/preprocessing',\n",
    "                    name=wav.removesuffix('.wav'),\n",
    "                    genre=genre\n",
    "                )\n",
    "                print(f'{count} - {wav} EXTRACTED')\n",
    "                count += 1\n",
    "            except:...\n",
    "\n",
    "\n",
    "PREPROCESSING = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(src: str, feature: str, test_size: float=0.3, \n",
    "              random_state: float = SEED_VALUE, shuffle: bool = True, \n",
    "              stratify: list = None):\n",
    "    \"\"\"\n",
    "        Divide the data set into three subsets, the training set, \\\n",
    "        the test set and the validation set.\n",
    "    \"\"\"\n",
    "    dataset = []\n",
    "\n",
    "    for genre in os.listdir(f'{src}/{feature}'):\n",
    "        for img in os.listdir(f'{src}/{feature}/{genre}'):\n",
    "            img = np.array(cv2.imread(f'{src}/{feature}/{genre}/{img}'), dtype=np.float32)\n",
    "            dataset.append([img, genre])\n",
    "\n",
    "    df = DataFrame(data=np.array(dataset), columns=[feature, 'genre'])\n",
    "\n",
    "    one_hot = pd.get_dummies(df['genre'])\n",
    "\n",
    "    df = pd.concat([df, one_hot], axis=1)\n",
    "    df.drop(['genre'], axis=1, inplace=True)\n",
    "    \n",
    "    strat = df[stratify] if stratify else None\n",
    "    train_set, test_set = train_test_split(df, test_size=test_size, random_state=random_state, \n",
    "                     shuffle=shuffle, stratify=strat)\n",
    "    \n",
    "    strat = test_set[stratify] if stratify else None\n",
    "    test_set, val_set = train_test_split(test_set, test_size=0.5, random_state=random_state, \n",
    "                     shuffle=shuffle, stratify=strat)\n",
    "\n",
    "    return (np.array([tf.convert_to_tensor(img) for img in train_set['mfcc']]), train_set[GENRES]) \\\n",
    "        , (np.array([tf.convert_to_tensor(img) for img in test_set['mfcc']]), test_set[GENRES]) \\\n",
    "        , (np.array([tf.convert_to_tensor(img) for img in val_set['mfcc']]), val_set[GENRES])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test), (X_val, y_val) = load_data('./dataset/preprocessing/', 'mfcc', stratify=GENRES)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=(3,3), input_shape=(326, 837, 3), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "\n",
    "model.compile(loss=SparseCategoricalCrossentropy(), \n",
    "              optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "history = model.fit(x=X_train, y=y_train, epochs=10, validation_data=(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
