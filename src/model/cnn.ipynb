{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music Genre Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'load_model' from 'keras.saving' (/home/leandro/.local/lib/python3.10/site-packages/keras/saving/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/home/leandro/study/projects/MuGenfier/src/model/cnn.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/leandro/study/projects/MuGenfier/src/model/cnn.ipynb#W1sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mimport\u001b[39;00m DataFrame\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/leandro/study/projects/MuGenfier/src/model/cnn.ipynb#W1sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m Sequential\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/leandro/study/projects/MuGenfier/src/model/cnn.ipynb#W1sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msaving\u001b[39;00m \u001b[39mimport\u001b[39;00m load_model\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/leandro/study/projects/MuGenfier/src/model/cnn.ipynb#W1sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m train_test_split\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/leandro/study/projects/MuGenfier/src/model/cnn.ipynb#W1sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m \u001b[39mimport\u001b[39;00m Flatten, Dense, Conv2D, MaxPool2D\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'load_model' from 'keras.saving' (/home/leandro/.local/lib/python3.10/site-packages/keras/saving/__init__.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import wget\n",
    "import random\n",
    "import shutil\n",
    "import tarfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from pandas import DataFrame\n",
    "from keras import Sequential\n",
    "from keras.saving import load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Flatten, Dense, Conv2D, MaxPool2D, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED_VALUE = 42\n",
    "\n",
    "# Fix seed to make training deterministic.\n",
    "random.seed(SEED_VALUE)\n",
    "np.random.seed(SEED_VALUE)\n",
    "tf.random.set_seed(SEED_VALUE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the GTZAN Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.getenv('COLAB_RELEASE_TAG'):\n",
    "    from google.colab import drive \n",
    "    drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREPROCESSING = False\n",
    "\n",
    "try:\n",
    "    if 'dataset' not in os.listdir('/content'):\n",
    "        os.mkdir('/content/dataset/')\n",
    "    pwd = os.getcwd()\n",
    "    os.chdir('/content/dataset/')\n",
    "\n",
    "    if os.getenv('COLAB_RELEASE_TAG'):\n",
    "        if 'preprocessing.tar.gz' in os.listdir('/content/gdrive/MyDrive'):\n",
    "            shutil.copy2('/content/gdrive/MyDrive/preprocessing.tar.gz', '.')\n",
    "        else:\n",
    "            # download the GTZAN dataset preprocessed\n",
    "            wget.download(\"https://drive.google.com/file/d/1UdmqcrBw71EgOtCLy6ic_C6EDBz9KQt_/view?usp=share_link\")\n",
    "    else:\n",
    "        if pwd != '/content/dataset':\n",
    "            if 'preprocessing.tar.gz' in os.listdir(f'{pwd}/dataset'):\n",
    "                shutil.copy2(f'{pwd}/dataset/preprocessing.tar.gz', '.')\n",
    "            else:\n",
    "                raise Exception(\"Download the GTZAN dataset preprocessed.\")\n",
    "\n",
    "    tar = tarfile.open('preprocessing.tar.gz', 'r:gz')\n",
    "    tar.extractall()\n",
    "    tar.close()\n",
    "\n",
    "finally:\n",
    "    GENRES = os.listdir('/content/dataset/preprocessing/mfcc')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(src: str, feature: str, test_size: float=0.3, \n",
    "              random_state: float = SEED_VALUE, shuffle: bool = True, \n",
    "              stratify: list = None):\n",
    "    \"\"\"\n",
    "        Divide the data set into three subsets, the training set, \\\n",
    "        the test set and the validation set.\n",
    "    \"\"\"\n",
    "    dataset = []\n",
    "    for genre in os.listdir(f'{src}/{feature}'):\n",
    "        for img in os.listdir(f'{src}/{feature}/{genre}'):\n",
    "            img = cv2.imread(f'{src}/{feature}/{genre}/{img}')\n",
    "            img = cv2.resize(img, (256, 192))\n",
    "            img = np.array(img, dtype=np.float32)\n",
    "            dataset.append([img, genre])\n",
    "\n",
    "    df = DataFrame(data=np.array(dataset, dtype=object), columns=[feature, 'genre'])\n",
    "\n",
    "    one_hot = pd.get_dummies(df['genre'])\n",
    "\n",
    "    df = pd.concat([df, one_hot], axis=1)\n",
    "    df.drop(['genre'], axis=1, inplace=True)\n",
    "    \n",
    "    strat = df[stratify] if stratify else None\n",
    "    train_set, test_set = train_test_split(df, test_size=test_size, random_state=random_state, \n",
    "                     shuffle=shuffle, stratify=strat)\n",
    "    \n",
    "    strat = test_set[stratify] if stratify else None\n",
    "    test_set, val_set = train_test_split(test_set, test_size=0.5, random_state=random_state, \n",
    "                     shuffle=shuffle, stratify=strat)\n",
    "\n",
    "    return (np.array([tf.convert_to_tensor(img) for img in train_set['mfcc']]), train_set[GENRES]) \\\n",
    "        , (np.array([tf.convert_to_tensor(img) for img in test_set['mfcc']]), test_set[GENRES]) \\\n",
    "        , (np.array([tf.convert_to_tensor(img) for img in val_set['mfcc']]), val_set[GENRES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/leandro/study/projects/MuGenfier/src/model/cnn.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/leandro/study/projects/MuGenfier/src/model/cnn.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m (X_train, y_train), (X_test, y_test), (X_val, y_val) \u001b[39m=\u001b[39m load_data(\u001b[39m'\u001b[39;49m\u001b[39m./preprocessing/\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mmfcc\u001b[39;49m\u001b[39m'\u001b[39;49m, stratify\u001b[39m=\u001b[39;49mGENRES)\n",
      "\u001b[1;32m/home/leandro/study/projects/MuGenfier/src/model/cnn.ipynb Cell 9\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(src, feature, test_size, random_state, shuffle, stratify)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/leandro/study/projects/MuGenfier/src/model/cnn.ipynb#X11sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mfor\u001b[39;00m genre \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mlistdir(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00msrc\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mfeature\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/leandro/study/projects/MuGenfier/src/model/cnn.ipynb#X11sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39mfor\u001b[39;00m img \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mlistdir(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00msrc\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mfeature\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mgenre\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/leandro/study/projects/MuGenfier/src/model/cnn.ipynb#X11sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m         img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mimread(\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m{\u001b[39;49;00msrc\u001b[39m}\u001b[39;49;00m\u001b[39m/\u001b[39;49m\u001b[39m{\u001b[39;49;00mfeature\u001b[39m}\u001b[39;49;00m\u001b[39m/\u001b[39;49m\u001b[39m{\u001b[39;49;00mgenre\u001b[39m}\u001b[39;49;00m\u001b[39m/\u001b[39;49m\u001b[39m{\u001b[39;49;00mimg\u001b[39m}\u001b[39;49;00m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/leandro/study/projects/MuGenfier/src/model/cnn.ipynb#X11sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m         img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mresize(img, (\u001b[39m256\u001b[39m, \u001b[39m192\u001b[39m))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/leandro/study/projects/MuGenfier/src/model/cnn.ipynb#X11sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m         img \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(img, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat32)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test), (X_val, y_val) = load_data('./preprocessing/', 'mfcc', stratify=GENRES)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=16, kernel_size=(3,3), activation='relu'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(filters=32, kernel_size=(3,3), input_shape=(192, 256, 3), activation='relu'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), activation='relu'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=256, activation='relu'))\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = []\n",
    "\n",
    "model_storage = '/content'\n",
    "\n",
    "if os.getenv('COLAB_RELEASE_TAG'):\n",
    "    model_storage = '/content/gdrive/MyDrive'\n",
    "\n",
    "if 'model_storage' not in os.listdir(model_storage):\n",
    "    os.mkdir('model_storage')\n",
    "\n",
    "last_iter = 0\n",
    "\n",
    "if len(os.listdir(f'{model_storage}/model_storage')) > 0:\n",
    "    last_iter = sorted([int(model.removeprefix('model_').removesuffix('.keras'))\n",
    "        for model in os.listdir(f'{model_storage}/model_storage')], reverse=True)[0]\n",
    "    model.load_model(f'{model_storage}/model_storage/model_{last_iter}.keras')\n",
    "\n",
    "for i in range(last_iter, 50):\n",
    "    history += model.fit(x=X_train, y=y_train, epochs=10, validation_data=(X_test, y_test))\n",
    "    model.save(f'{model_storage}/model_storage/model_{i}.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
