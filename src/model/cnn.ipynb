{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music Genre Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import wget\n",
    "import random\n",
    "import shutil\n",
    "import tarfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from pandas import DataFrame\n",
    "from keras import Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.losses import SparseCategoricalCrossentropy\n",
    "from keras.layers import Flatten, Dense, Conv2D, MaxPool2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED_VALUE = 42\n",
    "\n",
    "# Fix seed to make training deterministic.\n",
    "random.seed(SEED_VALUE)\n",
    "np.random.seed(SEED_VALUE)\n",
    "tf.random.set_seed(SEED_VALUE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the GTZAN Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.getenv('COLAB_RELEASE_TAG'):\n",
    "    from google.colab import drive \n",
    "    drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREPROCESSING = False\n",
    "\n",
    "try:\n",
    "    if 'dataset' not in os.listdir('/content'):\n",
    "        os.mkdir('/content/dataset/')\n",
    "    pwd = os.getcwd()\n",
    "    os.chdir('/content/dataset/')\n",
    "\n",
    "    if os.getenv('COLAB_RELEASE_TAG'):\n",
    "        if 'preprocessing.tar.gz' in os.listdir('/content/gdrive/MyDrive'):\n",
    "            shutil.copy2('/content/gdrive/MyDrive/preprocessing.tar.gz', '.')\n",
    "        else:\n",
    "            # download the GTZAN dataset preprocessed\n",
    "            wget.download(\"https://drive.google.com/file/d/1UdmqcrBw71EgOtCLy6ic_C6EDBz9KQt_/view?usp=share_link\")\n",
    "    else:\n",
    "        if 'preprocessing.tar.gz' in os.listdir(f'{pwd}/dataset'):\n",
    "            shutil.copy2(f'{pwd}/dataset/preprocessing.tar.gz', '.')\n",
    "        else:\n",
    "            raise Exception(\"Download the GTZAN dataset preprocessed.\")\n",
    "\n",
    "    tar = tarfile.open('preprocessing.tar.gz', 'r:gz')\n",
    "    tar.extractall()\n",
    "    tar.close()\n",
    "\n",
    "finally:\n",
    "    GENRES = os.listdir('/content/preprocessing/mfcc')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(src: str, feature: str, test_size: float=0.3, \n",
    "              random_state: float = SEED_VALUE, shuffle: bool = True, \n",
    "              stratify: list = None):\n",
    "    \"\"\"\n",
    "        Divide the data set into three subsets, the training set, \\\n",
    "        the test set and the validation set.\n",
    "    \"\"\"\n",
    "    dataset = []\n",
    "\n",
    "    for genre in os.listdir(f'{src}/{feature}'):\n",
    "        for img in os.listdir(f'{src}/{feature}/{genre}'):\n",
    "            img = np.array(cv2.imread(f'{src}/{feature}/{genre}/{img}'), dtype=np.float32)\n",
    "            dataset.append([img, genre])\n",
    "\n",
    "    df = DataFrame(data=np.array(dataset), columns=[feature, 'genre'])\n",
    "\n",
    "    one_hot = pd.get_dummies(df['genre'])\n",
    "\n",
    "    df = pd.concat([df, one_hot], axis=1)\n",
    "    df.drop(['genre'], axis=1, inplace=True)\n",
    "    \n",
    "    strat = df[stratify] if stratify else None\n",
    "    train_set, test_set = train_test_split(df, test_size=test_size, random_state=random_state, \n",
    "                     shuffle=shuffle, stratify=strat)\n",
    "    \n",
    "    strat = test_set[stratify] if stratify else None\n",
    "    test_set, val_set = train_test_split(test_set, test_size=0.5, random_state=random_state, \n",
    "                     shuffle=shuffle, stratify=strat)\n",
    "\n",
    "    return (np.array([tf.convert_to_tensor(img) for img in train_set['mfcc']]), train_set[GENRES]) \\\n",
    "        , (np.array([tf.convert_to_tensor(img) for img in test_set['mfcc']]), test_set[GENRES]) \\\n",
    "        , (np.array([tf.convert_to_tensor(img) for img in val_set['mfcc']]), val_set[GENRES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test), (X_val, y_val) = load_data('./dataset/preprocessing/', 'mfcc', stratify=GENRES)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=(3,3), input_shape=(326, 837, 3), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "\n",
    "model.compile(loss=SparseCategoricalCrossentropy(), \n",
    "              optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "history = model.fit(x=X_train, y=y_train, epochs=10, validation_data=(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
