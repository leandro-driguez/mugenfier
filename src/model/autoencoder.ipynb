{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oCF3wKMDNp6"
      },
      "source": [
        "# Music Genre Classifier\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-XfiDBNMDNp_",
        "outputId": "7de45f85-31c4-4753-fad2-10e1bc90bf4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: wget in /usr/local/lib/python3.10/dist-packages (3.2)\n"
          ]
        }
      ],
      "source": [
        "%pip install wget\n",
        "import os\n",
        "import cv2\n",
        "import wget\n",
        "import random\n",
        "import shutil\n",
        "import tarfile\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from pandas import DataFrame\n",
        "from keras import Sequential\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from keras.layers import Conv2D, UpSampling2D, MaxPooling2D, Input, Cropping2D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TrKBv-RiDNqB"
      },
      "outputs": [],
      "source": [
        "SEED_VALUE = 42\n",
        "\n",
        "# Fix seed to make training deterministic.\n",
        "random.seed(SEED_VALUE)\n",
        "np.random.seed(SEED_VALUE)\n",
        "tf.random.set_seed(SEED_VALUE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fq-JEy-vDNqB"
      },
      "source": [
        "## Load the GTZAN Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQ4Ip6g-DNqC",
        "outputId": "8ee3ab50-e88c-4e15-c1e7-b1a586ac1254"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "if os.getenv('COLAB_RELEASE_TAG'):\n",
        "    from google.colab import drive \n",
        "    drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "TurG6yZ1DNqC"
      },
      "outputs": [],
      "source": [
        "PREPROCESSING = False\n",
        "\n",
        "try:\n",
        "    if 'dataset' not in os.listdir('/content'):\n",
        "        os.mkdir('/content/dataset/')\n",
        "    pwd = os.getcwd()\n",
        "    os.chdir('/content/dataset/')\n",
        "\n",
        "    if 'preprocessing.tar.gz' not in os.listdir('.'):\n",
        "        if os.getenv('COLAB_RELEASE_TAG'):\n",
        "            if 'preprocessing.tar.gz' in os.listdir('/content/gdrive/MyDrive'):\n",
        "                shutil.copy2('/content/gdrive/MyDrive/preprocessing.tar.gz', '.')\n",
        "            else:\n",
        "                # make sure to download the GTZAN dataset from \"https://drive.google.com/file/d/1UdmqcrBw71EgOtCLy6ic_C6EDBz9KQt_/view?usp=share_link\"\n",
        "                # upload it to your own google drive for it to be copied in the previous if statement block\n",
        "                pass\n",
        "        else:\n",
        "            if pwd != '/content/dataset':\n",
        "                if 'preprocessing.tar.gz' in os.listdir(f'{pwd}/dataset'):\n",
        "                    shutil.copy2(f'{pwd}/dataset/preprocessing.tar.gz', '.')\n",
        "                else:\n",
        "                    raise Exception(\"Download the GTZAN dataset preprocessed.\")\n",
        "\n",
        "        tar = tarfile.open('preprocessing.tar.gz', 'r:gz')\n",
        "        tar.extractall()\n",
        "        tar.close()\n",
        "\n",
        "finally:\n",
        "    GENRES = os.listdir('/content/dataset/preprocessing/mfcc')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Jht-abLDNqD"
      },
      "source": [
        "## Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "VDRogc3lDNqD"
      },
      "outputs": [],
      "source": [
        "def load_data(src: str, feature: str, \n",
        "              random_state: float = SEED_VALUE, shuffle: bool = True, \n",
        "              stratify: list = None):\n",
        "    dataset = []\n",
        "    for genre in os.listdir(f'{src}/{feature}'):\n",
        "        for img in os.listdir(f'{src}/{feature}/{genre}'):\n",
        "            img = cv2.imread(f'{src}/{feature}/{genre}/{img}')\n",
        "            # img = cv2.resize(img, (256, 192))\n",
        "            img = np.array(img, dtype=np.float32)\n",
        "            dataset.append([img, genre])\n",
        "\n",
        "    df = DataFrame(data=np.array(dataset, dtype=object), columns=[feature, 'genre'])\n",
        "\n",
        "    one_hot = pd.get_dummies(df['genre'])\n",
        "\n",
        "    df = pd.concat([df, one_hot], axis=1)\n",
        "    df.drop(['genre'], axis=1, inplace=True)\n",
        "    \n",
        "    strat = df[stratify] if stratify else None\n",
        "    train_set, test_set = train_test_split(df, test_size=0.5, random_state=random_state, \n",
        "                     shuffle=shuffle, stratify=strat)\n",
        "\n",
        "    train_set=train_set+test_set\n",
        "\n",
        "    return (np.array([tf.convert_to_tensor(img) for img in train_set['mfcc']]), train_set[GENRES])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "gfOsnG1BDNqE"
      },
      "outputs": [],
      "source": [
        "(X_train, _) = load_data('./preprocessing/', 'mfcc', stratify=GENRES)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXuwBf8uDNqE"
      },
      "source": [
        "## CNN\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "nt2KtEizDNqF"
      },
      "outputs": [],
      "source": [
        "\n",
        "def generate_autoencoder():\n",
        "    input_l=Input(shape=(217,334,3))\n",
        "    encoding_1=Conv2D(48, (3,3), activation='relu',padding='same')(input_l)\n",
        "\n",
        "    maxp_1=MaxPooling2D((2,2), padding='same')(encoding_1)\n",
        "    encoding_2=Conv2D(24, (3,3), activation='relu',padding='same')(maxp_1)\n",
        "\n",
        "    maxp_2=MaxPooling2D((2,2), padding='same')(encoding_2)\n",
        "    encoding_3=Conv2D(12, (3,3), activation='relu',padding='same')(maxp_2)\n",
        "\n",
        "    maxp_3=MaxPooling2D((2,2), padding='same')(encoding_3)\n",
        "    encoding_4=Conv2D(6, (3,3), activation='relu',padding='same')(maxp_3)\n",
        "\n",
        "    bottleneck=MaxPooling2D((2,2), padding='same')(encoding_4)\n",
        "\n",
        "    decoding_1=Conv2D(6, (3,3), activation='relu', padding='same')(bottleneck)\n",
        "    Up_1=UpSampling2D((2,2))(decoding_1)\n",
        "\n",
        "    decoding_2=Conv2D(12, (3,3), activation='relu', padding='same')(Up_1)\n",
        "    Up_2=UpSampling2D((2,2))(decoding_2)\n",
        "    Crop_1=Cropping2D(cropping=((0, 1),(0, 0))) (Up_2)\n",
        "\n",
        "    decoding_3=Conv2D(24, (3,3), activation='relu', padding='same')(Crop_1)\n",
        "    Up_3=UpSampling2D((2,2))(decoding_3)\n",
        "    Crop_2=Cropping2D(cropping=((0, 1),(0, 1))) (Up_3)\n",
        "\n",
        "    decoding_4=Conv2D(48, (3,3), activation='relu', padding='same')(Crop_2)\n",
        "    Up_4=UpSampling2D((2,2))(decoding_4)\n",
        "    Crop_3=Cropping2D(cropping=((0, 1),(0, 0))) (Up_4)\n",
        "\n",
        "    output_l= Conv2D(3,(3,3),activation='relu',padding='same')(Crop_3)\n",
        "\n",
        "    autoencoder=Model(inputs=[input_l],outputs=[output_l])\n",
        "\n",
        "    autoencoder.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_squared_error'])\n",
        "\n",
        "    return autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBeIyu3iDNqF",
        "outputId": "e5ed92a9-7fd6-41ec-c3e1-15d3b9076f82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 217, 334, 3)]     0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 217, 334, 48)      1344      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 109, 167, 48)     0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 109, 167, 24)      10392     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 55, 84, 24)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 55, 84, 12)        2604      \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 28, 42, 12)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 28, 42, 6)         654       \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 14, 21, 6)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 14, 21, 6)         330       \n",
            "                                                                 \n",
            " up_sampling2d (UpSampling2D  (None, 28, 42, 6)        0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 28, 42, 12)        660       \n",
            "                                                                 \n",
            " up_sampling2d_1 (UpSampling  (None, 56, 84, 12)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " cropping2d (Cropping2D)     (None, 55, 84, 12)        0         \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 55, 84, 24)        2616      \n",
            "                                                                 \n",
            " up_sampling2d_2 (UpSampling  (None, 110, 168, 24)     0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " cropping2d_1 (Cropping2D)   (None, 109, 167, 24)      0         \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 109, 167, 48)      10416     \n",
            "                                                                 \n",
            " up_sampling2d_3 (UpSampling  (None, 218, 334, 48)     0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " cropping2d_2 (Cropping2D)   (None, 217, 334, 48)      0         \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 217, 334, 3)       1299      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 30,315\n",
            "Trainable params: 30,315\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "generate_autoencoder().summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jhu2oqEMDNqF",
        "outputId": "2c32a88c-2194-439a-954d-b80a973d515e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            " 8/32 [======>.......................] - ETA: 6:15 - loss: nan - mean_squared_error: nan"
          ]
        }
      ],
      "source": [
        "history = []\n",
        "\n",
        "model_storage = '/content'\n",
        "\n",
        "if os.getenv('COLAB_RELEASE_TAG'):\n",
        "    model_storage = '/content/gdrive/MyDrive'\n",
        "\n",
        "if 'model_storage' not in os.listdir(model_storage):\n",
        "    os.mkdir(f'{model_storage}/model_storage')\n",
        "\n",
        "autoencoder = generate_autoencoder()\n",
        "last_iter = 0\n",
        "\n",
        "if len(os.listdir(f'{model_storage}/model_storage')) > 0:\n",
        "    last_iter = sorted([int(autoencoder.removeprefix(f'autoencoder_model_').removesuffix('.keras'))\n",
        "        for autoencoder in os.listdir(f'{model_storage}/model_storage')], reverse=True)[0]\n",
        "    autoencoder = tf.keras.saving.load_model(f'{model_storage}/model_storage/autoencoder_model_{last_iter}.keras')\n",
        "\n",
        "for i in range(last_iter, 250):\n",
        "    history.append(autoencoder.fit(x=X_train, y=X_train, epochs=2))\n",
        "    autoencoder.save(f'{model_storage}/model_storage/autoencoder_model_{i}.keras')\n",
        "\n",
        "kfold=KFold(n_splits=10, shuffle=True)\n",
        "fold_no=1\n",
        "final_errors_per_fold=[]\n",
        "\n",
        "for train, _ in kfold.split(X_train, X_train):\n",
        "    last_iter = 0\n",
        "\n",
        "    autoencoder = generate_autoencoder()\n",
        "\n",
        "    if len(os.listdir(f'{model_storage}/model_storage')) > 0:\n",
        "        last_iter = sorted([int(autoencoder.removeprefix(f'autoencoder_model_{fold_no}_').removesuffix('.keras'))\n",
        "            for autoencoder in os.listdir(f'{model_storage}/model_storage')], reverse=True)[0]\n",
        "        autoencoder = tf.keras.saving.load_model(f'{model_storage}/model_storage/autoencoder_model_{fold_no}_{last_iter}.keras')\n",
        "\n",
        "    for i in range(last_iter, 250):\n",
        "        history.append(autoencoder.fit(x=X_train[train], y=X_train[train], epochs=2))\n",
        "        autoencoder.save(f'{model_storage}/model_storage/autoencoder_model_{i}.keras')\n",
        "    \n",
        "    # Generate generalization metrics\n",
        "    scores = autoencoder.evaluate(X_train, X_train, verbose=0)\n",
        "    print(f'Score for fold {fold_no}: {autoencoder.metrics_names[0]} of {scores[0]}')\n",
        "    final_errors_per_fold.append(scores[0])\n",
        "\n",
        "    # Increase fold number\n",
        "    fold_no = fold_no + 1"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}