{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oCF3wKMDNp6"
      },
      "source": [
        "# Music Genre Classifier\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-XfiDBNMDNp_",
        "outputId": "263bf4ce-ed51-404f-c9d8-c7cd0cdfe3fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: wget in /usr/local/lib/python3.10/dist-packages (3.2)\n"
          ]
        }
      ],
      "source": [
        "%pip install wget\n",
        "import os\n",
        "import cv2\n",
        "import wget\n",
        "import random\n",
        "import shutil\n",
        "import tarfile\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from pandas import DataFrame\n",
        "from keras import Sequential\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from keras.layers import Conv2D, UpSampling2D, MaxPooling2D, Input, Cropping2D, Cropping3D, Flatten, Dense, Reshape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "TrKBv-RiDNqB"
      },
      "outputs": [],
      "source": [
        "SEED_VALUE = 42\n",
        "\n",
        "# Fix seed to make training deterministic.\n",
        "random.seed(SEED_VALUE)\n",
        "np.random.seed(SEED_VALUE)\n",
        "tf.random.set_seed(SEED_VALUE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fq-JEy-vDNqB"
      },
      "source": [
        "## Load the GTZAN Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQ4Ip6g-DNqC",
        "outputId": "7e5bfb31-e4c4-4543-a980-83cfd8ffe87d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "if os.getenv('COLAB_RELEASE_TAG'):\n",
        "    from google.colab import drive \n",
        "    drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "TurG6yZ1DNqC"
      },
      "outputs": [],
      "source": [
        "PREPROCESSING = False\n",
        "\n",
        "try:\n",
        "    if 'dataset' not in os.listdir('/content'):\n",
        "        os.mkdir('/content/dataset/')\n",
        "    pwd = os.getcwd()\n",
        "    os.chdir('/content/dataset/')\n",
        "\n",
        "    if 'preprocessing.tar.gz' not in os.listdir('.'):\n",
        "        if os.getenv('COLAB_RELEASE_TAG'):\n",
        "            if 'preprocessing.tar.gz' in os.listdir('/content/gdrive/MyDrive'):\n",
        "                shutil.copy2('/content/gdrive/MyDrive/preprocessing.tar.gz', '.')\n",
        "            else:\n",
        "                # make sure to download the GTZAN dataset from \"https://drive.google.com/file/d/1UdmqcrBw71EgOtCLy6ic_C6EDBz9KQt_/view?usp=share_link\"\n",
        "                # upload it to your own google drive for it to be copied in the previous if statement block\n",
        "                pass\n",
        "        else:\n",
        "            if pwd != '/content/dataset':\n",
        "                if 'preprocessing.tar.gz' in os.listdir(f'{pwd}/dataset'):\n",
        "                    shutil.copy2(f'{pwd}/dataset/preprocessing.tar.gz', '.')\n",
        "                else:\n",
        "                    raise Exception(\"Download the GTZAN dataset preprocessed.\")\n",
        "\n",
        "        tar = tarfile.open('preprocessing.tar.gz', 'r:gz')\n",
        "        tar.extractall()\n",
        "        tar.close()\n",
        "\n",
        "finally:\n",
        "    GENRES = os.listdir('/content/dataset/preprocessing/mfcc')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Jht-abLDNqD"
      },
      "source": [
        "## Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "VDRogc3lDNqD"
      },
      "outputs": [],
      "source": [
        "def load_data(src: str, feature: str, \n",
        "              random_state: float = SEED_VALUE, shuffle: bool = True, \n",
        "              stratify: list = None):\n",
        "    dataset = []\n",
        "    for genre in os.listdir(f'{src}/{feature}'):\n",
        "        for img in os.listdir(f'{src}/{feature}/{genre}'):\n",
        "            img = cv2.imread(f'{src}/{feature}/{genre}/{img}')\n",
        "            # img = cv2.resize(img, (256, 192))\n",
        "            img = np.array(img, dtype=np.float32)\n",
        "            dataset.append([img, genre])\n",
        "\n",
        "    df = DataFrame(data=np.array(dataset, dtype=object), columns=[feature, 'genre'])\n",
        "\n",
        "    one_hot = pd.get_dummies(df['genre'])\n",
        "\n",
        "    df = pd.concat([df, one_hot], axis=1)\n",
        "    df.drop(['genre'], axis=1, inplace=True)\n",
        "    \n",
        "    strat = df[stratify] if stratify else None\n",
        "    train_set, test_set = train_test_split(df, test_size=0.5, random_state=random_state, \n",
        "                     shuffle=shuffle, stratify=strat)\n",
        "\n",
        "    return (np.array([tf.convert_to_tensor(img) for img in train_set['mfcc']]), train_set[GENRES])\\\n",
        "          , (np.array([tf.convert_to_tensor(img) for img in train_set['mfcc']]), test_set[GENRES])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "gfOsnG1BDNqE"
      },
      "outputs": [],
      "source": [
        "(X_train, _), (X_test, _) = load_data('./preprocessing/', 'mfcc', stratify=GENRES)\n",
        "\n",
        "# for cross validation purposes it is encouraged to concatenate all input/output data, in this case, only input\n",
        "X_train = np.concatenate((X_train, X_test), axis=0)\n",
        "# this is just to normalize the values between 0 and 1\n",
        "X_train = X_train / 255"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXuwBf8uDNqE"
      },
      "source": [
        "## CNN Autoencoder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "nt2KtEizDNqF"
      },
      "outputs": [],
      "source": [
        "def generate_autoencoder():\n",
        "    input_l=Input(shape=(217,334,3))\n",
        "\n",
        "    maxp_ini=MaxPooling2D((4,6), padding='same')(input_l)\n",
        "    encoding_1=Conv2D(12, (3,3), activation='relu',padding='same')(maxp_ini)\n",
        "\n",
        "    maxp_1=MaxPooling2D((2,2), padding='same')(encoding_1)\n",
        "    encoding_2=Conv2D(6, (3,3), activation='relu',padding='same')(maxp_1)\n",
        "\n",
        "    maxp_2=MaxPooling2D((2,2), padding='same')(encoding_2)\n",
        "    encoding_3=Conv2D(3, (3,3), activation='relu',padding='same')(maxp_2)\n",
        "\n",
        "    bottleneck=MaxPooling2D((2,2), padding='same')(encoding_3)\n",
        "\n",
        "    decoding_2=Conv2D(3, (3,3), activation='relu', padding='same')(bottleneck)\n",
        "    Up_2=UpSampling2D((2,2))(decoding_2)\n",
        "\n",
        "    decoding_3=Conv2D(6, (3,3), activation='relu', padding='same')(Up_2)\n",
        "    Up_3=UpSampling2D((2,2))(decoding_3)\n",
        "\n",
        "    decoding_4=Conv2D(12, (3,3), activation='relu', padding='same')(Up_3)\n",
        "    Up_4=UpSampling2D((2,2))(decoding_4)\n",
        "    crop_1=Cropping2D(((0,1), (0,0)))(Up_4)\n",
        "\n",
        "    decoding_5= Conv2D(3,(3,3),activation='sigmoid',padding='same')(crop_1)\n",
        "    up_out=UpSampling2D((4,6))(decoding_5)\n",
        "    output_l=Cropping2D(((0,3), (0,2)))(up_out)\n",
        "\n",
        "    autoencoder=Model(inputs=[input_l],outputs=[output_l])\n",
        "\n",
        "    autoencoder.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_squared_error'])\n",
        "\n",
        "    return autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBeIyu3iDNqF",
        "outputId": "a4e7af97-adf4-4ab4-fc16-47a9fbc0853a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_28\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_32 (InputLayer)       [(None, 217, 334, 3)]     0         \n",
            "                                                                 \n",
            " max_pooling2d_16 (MaxPoolin  (None, 55, 56, 3)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_28 (Conv2D)          (None, 55, 56, 12)        336       \n",
            "                                                                 \n",
            " max_pooling2d_17 (MaxPoolin  (None, 28, 28, 12)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_29 (Conv2D)          (None, 28, 28, 6)         654       \n",
            "                                                                 \n",
            " max_pooling2d_18 (MaxPoolin  (None, 14, 14, 6)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_30 (Conv2D)          (None, 14, 14, 3)         165       \n",
            "                                                                 \n",
            " max_pooling2d_19 (MaxPoolin  (None, 7, 7, 3)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_31 (Conv2D)          (None, 7, 7, 3)           84        \n",
            "                                                                 \n",
            " up_sampling2d_16 (UpSamplin  (None, 14, 14, 3)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_32 (Conv2D)          (None, 14, 14, 6)         168       \n",
            "                                                                 \n",
            " up_sampling2d_17 (UpSamplin  (None, 28, 28, 6)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_33 (Conv2D)          (None, 28, 28, 12)        660       \n",
            "                                                                 \n",
            " up_sampling2d_18 (UpSamplin  (None, 56, 56, 12)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " cropping2d_8 (Cropping2D)   (None, 55, 56, 12)        0         \n",
            "                                                                 \n",
            " conv2d_34 (Conv2D)          (None, 55, 56, 3)         327       \n",
            "                                                                 \n",
            " up_sampling2d_19 (UpSamplin  (None, 220, 336, 3)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " cropping2d_9 (Cropping2D)   (None, 217, 334, 3)       0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,394\n",
            "Trainable params: 2,394\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "generate_autoencoder().summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_storage = '/content'\n",
        "\n",
        "if os.getenv('COLAB_RELEASE_TAG'):\n",
        "    model_storage = '/content/gdrive/MyDrive'\n",
        "\n",
        "if 'model_storage' not in os.listdir(model_storage):\n",
        "    os.mkdir(f'{model_storage}/model_storage')"
      ],
      "metadata": {
        "id": "gr4CfUOO7xgb"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and Cross Validating"
      ],
      "metadata": {
        "id": "6kSY-S-Z3ZCX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jhu2oqEMDNqF",
        "outputId": "d2d7e9db-403e-455d-ef6a-2263bd876769"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score for fold 1: loss of 0.002612202661111951\n",
            "Epoch 1/10\n",
            "29/29 [==============================] - 16s 525ms/step - loss: 0.0033 - mean_squared_error: 0.0033\n",
            "Epoch 2/10\n",
            "29/29 [==============================] - 16s 551ms/step - loss: 0.0033 - mean_squared_error: 0.0033\n",
            "Epoch 3/10\n",
            "29/29 [==============================] - 15s 516ms/step - loss: 0.0033 - mean_squared_error: 0.0033\n",
            "Epoch 4/10\n",
            "29/29 [==============================] - 15s 518ms/step - loss: 0.0033 - mean_squared_error: 0.0033\n",
            "Epoch 5/10\n",
            "29/29 [==============================] - 15s 516ms/step - loss: 0.0033 - mean_squared_error: 0.0033\n",
            "Epoch 6/10\n",
            "29/29 [==============================] - 15s 511ms/step - loss: 0.0033 - mean_squared_error: 0.0033\n",
            "Epoch 7/10\n",
            "29/29 [==============================] - 15s 511ms/step - loss: 0.0032 - mean_squared_error: 0.0032\n",
            "Epoch 8/10\n",
            "29/29 [==============================] - 15s 512ms/step - loss: 0.0032 - mean_squared_error: 0.0032\n",
            "Epoch 9/10\n",
            "29/29 [==============================] - 15s 517ms/step - loss: 0.0032 - mean_squared_error: 0.0032\n",
            "Epoch 10/10\n",
            "29/29 [==============================] - 15s 511ms/step - loss: 0.0032 - mean_squared_error: 0.0032\n",
            "Epoch 1/10\n",
            "29/29 [==============================] - 15s 518ms/step - loss: 0.0032 - mean_squared_error: 0.0032\n",
            "Epoch 2/10\n",
            "29/29 [==============================] - 15s 514ms/step - loss: 0.0032 - mean_squared_error: 0.0032\n",
            "Epoch 3/10\n",
            "29/29 [==============================] - 15s 508ms/step - loss: 0.0032 - mean_squared_error: 0.0032\n",
            "Epoch 4/10\n",
            "29/29 [==============================] - 15s 512ms/step - loss: 0.0032 - mean_squared_error: 0.0032\n",
            "Epoch 5/10\n",
            "29/29 [==============================] - 15s 510ms/step - loss: 0.0032 - mean_squared_error: 0.0032\n",
            "Epoch 6/10\n",
            "29/29 [==============================] - 15s 511ms/step - loss: 0.0032 - mean_squared_error: 0.0032\n",
            "Epoch 7/10\n",
            "29/29 [==============================] - 15s 511ms/step - loss: 0.0032 - mean_squared_error: 0.0032\n",
            "Epoch 8/10\n",
            "29/29 [==============================] - 15s 511ms/step - loss: 0.0032 - mean_squared_error: 0.0032\n",
            "Epoch 9/10\n",
            "29/29 [==============================] - 15s 509ms/step - loss: 0.0032 - mean_squared_error: 0.0032\n",
            "Epoch 10/10\n",
            "29/29 [==============================] - 15s 495ms/step - loss: 0.0032 - mean_squared_error: 0.0032\n",
            "Epoch 1/10\n",
            "29/29 [==============================] - 15s 509ms/step - loss: 0.0032 - mean_squared_error: 0.0032\n",
            "Epoch 2/10\n",
            "29/29 [==============================] - 15s 509ms/step - loss: 0.0032 - mean_squared_error: 0.0032\n",
            "Epoch 3/10\n",
            "29/29 [==============================] - 15s 504ms/step - loss: 0.0032 - mean_squared_error: 0.0032\n",
            "Epoch 4/10\n",
            "29/29 [==============================] - 15s 508ms/step - loss: 0.0032 - mean_squared_error: 0.0032\n",
            "Epoch 5/10\n",
            "29/29 [==============================] - 15s 505ms/step - loss: 0.0032 - mean_squared_error: 0.0032\n",
            "Epoch 6/10\n",
            "29/29 [==============================] - 15s 509ms/step - loss: 0.0032 - mean_squared_error: 0.0032\n",
            "Epoch 7/10\n",
            "29/29 [==============================] - 15s 506ms/step - loss: 0.0032 - mean_squared_error: 0.0032\n",
            "Epoch 8/10\n",
            "29/29 [==============================] - 14s 490ms/step - loss: 0.0032 - mean_squared_error: 0.0032\n",
            "Epoch 9/10\n",
            "29/29 [==============================] - 14s 488ms/step - loss: 0.0032 - mean_squared_error: 0.0032\n",
            "Epoch 10/10\n",
            "29/29 [==============================] - 14s 489ms/step - loss: 0.0031 - mean_squared_error: 0.0031\n",
            "Epoch 1/10\n",
            "29/29 [==============================] - 15s 506ms/step - loss: 0.0031 - mean_squared_error: 0.0031\n",
            "Epoch 2/10\n",
            "29/29 [==============================] - 14s 496ms/step - loss: 0.0031 - mean_squared_error: 0.0031\n",
            "Epoch 3/10\n",
            "29/29 [==============================] - 14s 495ms/step - loss: 0.0031 - mean_squared_error: 0.0031\n",
            "Epoch 4/10\n",
            "22/29 [=====================>........] - ETA: 3s - loss: 0.0031 - mean_squared_error: 0.0031"
          ]
        }
      ],
      "source": [
        "history = []\n",
        "\n",
        "autoencoder = generate_autoencoder()\n",
        "last_iter = 0\n",
        "\n",
        "if len(os.listdir(f'{model_storage}/model_storage')) > 0:\n",
        "    last_iter = sorted([int(autoencoder.removeprefix(f'autoencoder_model_').removesuffix('.keras'))\n",
        "        for autoencoder in os.listdir(f'{model_storage}/model_storage') if autoencoder[0]=='a'], reverse=True)[0]\n",
        "    autoencoder = tf.keras.saving.load_model(f'{model_storage}/model_storage/autoencoder_model_{last_iter}.keras')\n",
        "    last_iter+=1 #this is for not overwriting the last saved model\n",
        "\n",
        "for i in range(last_iter, 50):\n",
        "    history.append(autoencoder.fit(x=X_train, y=X_train, epochs=10))\n",
        "    autoencoder.save(f'{model_storage}/model_storage/autoencoder_model_{i}.keras')\n",
        "\n",
        "kfold=KFold(n_splits=10, shuffle=True)\n",
        "fold_no=1\n",
        "final_errors_per_fold=[]\n",
        "\n",
        "for train, test in kfold.split(X_train, X_train):\n",
        "    last_iter = 0\n",
        "\n",
        "    autoencoder = generate_autoencoder()\n",
        "\n",
        "    if f'fold_{fold_no}' not in os.listdir(f'{model_storage}/model_storage'):\n",
        "        os.mkdir(f'{model_storage}/model_storage/fold_{fold_no}')\n",
        "\n",
        "    if len(os.listdir(f'{model_storage}/model_storage/fold_{fold_no}')) > 0:\n",
        "        last_iter = sorted([int(autoencoder.removeprefix(f'autoencoder_model_').removesuffix('.keras'))\n",
        "            for autoencoder in os.listdir(f'{model_storage}/model_storage/fold_{fold_no}')], reverse=True)[0]\n",
        "        autoencoder = tf.keras.saving.load_model(f'{model_storage}/model_storage/fold_{fold_no}/autoencoder_model_{last_iter}.keras')\n",
        "        last_iter+=1 #this is for not overwriting the last saved model\n",
        "\n",
        "    for i in range(last_iter, 50):\n",
        "        history.append(autoencoder.fit(x=X_train[train], y=X_train[train], epochs=10))\n",
        "        autoencoder.save(f'{model_storage}/model_storage/fold_{fold_no}/autoencoder_model_{i}.keras')\n",
        "\n",
        "    # Generate generalization metrics\n",
        "    scores = autoencoder.evaluate(X_train[test], X_train[test], verbose=0)\n",
        "    print(f'Score for fold {fold_no}: {autoencoder.metrics_names[0]} of {scores[0]}')\n",
        "    final_errors_per_fold.append(scores[0])\n",
        "\n",
        "    # Increase fold number\n",
        "    fold_no = fold_no + 1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoder"
      ],
      "metadata": {
        "id": "LNqDoyxy1iMY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# if necessary, download this precise autoencoder model from https://drive.google.com/file/d/1oWJtDdYOnT9rVYcnzlTBC3SJEBq41p-H/view?usp=sharing\n",
        "if 'autoencoder_model_49.keras' not in os.listdir(f'{model_storage}/model_storage'):\n",
        "    print(f'Not finished optimizing: autoencoder_model_49.keras not found in {model_storage}/model_storage.')\n",
        "else:\n",
        "    autoencoder = tf.keras.saving.load_model(f'{model_storage}/model_storage/autoencoder_model_49.keras')\n",
        "    encoder_input_l = Input(shape=(217,334,3))\n",
        "    res_1 = autoencoder.layers[1](encoder_input_l)\n",
        "    res_2 = autoencoder.layers[2](res_1)\n",
        "    res_3 = autoencoder.layers[3](res_2)\n",
        "    res_4 = autoencoder.layers[4](res_3)\n",
        "    res_5 = autoencoder.layers[5](res_4)\n",
        "    res_6 = autoencoder.layers[6](res_5)\n",
        "    res_7 = autoencoder.layers[7](res_6)\n",
        "    # For some reason the first channel of the every encoding returns 0, so we'll take it out\n",
        "    reshape_l1 = Reshape(target_shape=(7, 7, 3, 1)) (res_7)\n",
        "    cropping_l = Cropping3D(((0, 0), (0, 0), (1, 0))) (reshape_l1)\n",
        "    reshape_l2 = Reshape(target_shape=(7, 7, 2, 1)) (cropping_l)\n",
        "    encoder_output_l = Flatten()(reshape_l2)\n",
        "    encoder=Model(inputs=[encoder_input_l],outputs=[encoder_output_l])\n",
        "    # encoder is already saved at https://drive.google.com/file/d/1rijbXEhqughprwFi-N00csI1tRkLr-p8/view?usp=sharing\n",
        "    encoder.save(f'{model_storage}/model_storage/encoder_model.keras')\n",
        "\n",
        "    print(encoder(X_train[:1])) # test\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emTGNskG2c_6",
        "outputId": "d5302d58-5104-4dd4-ef27-7be66a0d900a"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[0.48886928 0.42168018 0.48452303 0.3872243  0.4562108  0.38743228\n",
            "  0.46328247 0.40348303 0.4656453  0.4006004  0.468429   0.39216167\n",
            "  0.49295703 0.43239418 0.38917184 0.5591275  0.37219787 0.5076032\n",
            "  0.36908293 0.49033305 0.35652226 0.4892758  0.34592035 0.494827\n",
            "  0.34394217 0.49516535 0.34770793 0.50194806 0.44187835 0.63676345\n",
            "  0.38193563 0.6137222  0.39638764 0.5849194  0.41019332 0.5839056\n",
            "  0.41821408 0.57456815 0.39890087 0.5881196  0.4075479  0.5838381\n",
            "  0.48673102 0.7150291  0.47722837 0.68987393 0.4776282  0.6995964\n",
            "  0.4931775  0.7197758  0.48436156 0.726348   0.466303   0.7223091\n",
            "  0.4516628  0.7179196  0.5034404  0.76586473 0.52083033 0.7368886\n",
            "  0.5622438  0.7444346  0.5575884  0.7239367  0.5556451  0.7423751\n",
            "  0.5439823  0.74527556 0.54464996 0.7154896  0.52632797 0.47846657\n",
            "  0.4837418  0.37268925 0.51215875 0.35443795 0.5183003  0.3947485\n",
            "  0.5279131  0.3932616  0.54134476 0.34726214 0.5170207  0.33671856\n",
            "  0.4031814  0.21641904 0.39854756 0.25519097 0.38269177 0.34343404\n",
            "  0.39657566 0.3196869  0.37027204 0.29523087 0.44091567 0.33031517\n",
            "  0.35767677 0.36856616]], shape=(1, 98), dtype=float32)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}